{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.metrics import jaccard_distance, edit_distance\n",
    "from nltk.parse.corenlp import CoreNLPDependencyParser\n",
    "parser = CoreNLPDependencyParser(url='http://localhost:9000')\n",
    "from scipy.stats import pearsonr\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'id1\\tThe bird is bathing in the sink.\\tBirdie is washing itself in the water basin.\\nid2\\tIn May 2010, the troops attempted to invade Kabul.\\tThe US army invaded Kabul on May 7th last year, 2010.\\nid3\\tJohn said he is considered a witness but not a suspect.\\t\"He is not a suspect anymore.\" John said.\\nid4\\tThey flew out of the nest in groups.\\tThey flew into the nest together.\\nid5\\tThe woman is playing the violin.\\tThe young lady enjoys listening to the guitar.\\nid6\\tJohn went horse back riding at dawn with a whole group of friends.\\tSunrise at dawn is a magnificent view to take in if you wake up early enough for it.\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('./given/trial/STS.input.txt') as input:\n",
    "    corpus = input.read()\n",
    "corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Divide the text into pairs of sentences\n",
    "We take the text and split it by their id, getting pairs of sentences separated by a tab, later we split those sentences by tat tab. Finally we calculate the triplets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[[(('bathing', 'NN'), 'nsubj', ('bird', 'NN')),\n",
       "   (('bird', 'NN'), 'det', ('The', 'DT')),\n",
       "   (('bathing', 'NN'), 'cop', ('is', 'VBZ')),\n",
       "   (('bathing', 'NN'), 'nmod', ('sink', 'NN')),\n",
       "   (('sink', 'NN'), 'case', ('in', 'IN')),\n",
       "   (('sink', 'NN'), 'det', ('the', 'DT')),\n",
       "   (('bathing', 'NN'), 'punct', ('.', '.'))],\n",
       "  [(('washing', 'VBG'), 'nsubj', ('Birdie', 'NNP')),\n",
       "   (('washing', 'VBG'), 'aux', ('is', 'VBZ')),\n",
       "   (('washing', 'VBG'), 'dobj', ('itself', 'PRP')),\n",
       "   (('washing', 'VBG'), 'nmod', ('basin', 'NN')),\n",
       "   (('basin', 'NN'), 'case', ('in', 'IN')),\n",
       "   (('basin', 'NN'), 'det', ('the', 'DT')),\n",
       "   (('basin', 'NN'), 'compound', ('water', 'NN')),\n",
       "   (('washing', 'VBG'), 'punct', ('.', '.'))]],\n",
       " [[(('attempted', 'VBN'), 'nmod', ('May', 'NNP')),\n",
       "   (('May', 'NNP'), 'case', ('In', 'IN')),\n",
       "   (('May', 'NNP'), 'nummod', ('2010', 'CD')),\n",
       "   (('attempted', 'VBN'), 'punct', (',', ',')),\n",
       "   (('attempted', 'VBN'), 'nsubj', ('troops', 'NNS')),\n",
       "   (('troops', 'NNS'), 'det', ('the', 'DT')),\n",
       "   (('attempted', 'VBN'), 'xcomp', ('invade', 'VB')),\n",
       "   (('invade', 'VB'), 'mark', ('to', 'TO')),\n",
       "   (('invade', 'VB'), 'dobj', ('Kabul', 'NNP')),\n",
       "   (('attempted', 'VBN'), 'punct', ('.', '.'))],\n",
       "  [(('invaded', 'VBD'), 'nsubj', ('army', 'NN')),\n",
       "   (('army', 'NN'), 'det', ('The', 'DT')),\n",
       "   (('army', 'NN'), 'compound', ('US', 'NNP')),\n",
       "   (('invaded', 'VBD'), 'dobj', ('Kabul', 'NNP')),\n",
       "   (('invaded', 'VBD'), 'nmod', ('7th', 'NNP')),\n",
       "   (('7th', 'NNP'), 'case', ('on', 'IN')),\n",
       "   (('7th', 'NNP'), 'compound', ('May', 'NNP')),\n",
       "   (('invaded', 'VBD'), 'nmod:tmod', ('year', 'NN')),\n",
       "   (('year', 'NN'), 'amod', ('last', 'JJ')),\n",
       "   (('invaded', 'VBD'), 'punct', (',', ',')),\n",
       "   (('invaded', 'VBD'), 'dobj', ('2010', 'CD')),\n",
       "   (('invaded', 'VBD'), 'punct', ('.', '.'))]],\n",
       " [[(('said', 'VBD'), 'nsubj', ('John', 'NNP')),\n",
       "   (('said', 'VBD'), 'ccomp', ('considered', 'VBN')),\n",
       "   (('considered', 'VBN'), 'nsubjpass', ('he', 'PRP')),\n",
       "   (('considered', 'VBN'), 'auxpass', ('is', 'VBZ')),\n",
       "   (('considered', 'VBN'), 'xcomp', ('witness', 'NN')),\n",
       "   (('witness', 'NN'), 'det', ('a', 'DT')),\n",
       "   (('witness', 'NN'), 'cc', ('not', 'RB')),\n",
       "   (('not', 'RB'), 'cc', ('but', 'CC')),\n",
       "   (('witness', 'NN'), 'conj', ('suspect', 'NN')),\n",
       "   (('suspect', 'NN'), 'det', ('a', 'DT')),\n",
       "   (('said', 'VBD'), 'punct', ('.', '.'))],\n",
       "  [(('``', '``'), 'root', ('suspect', 'JJ')),\n",
       "   (('suspect', 'JJ'), 'nsubj', ('He', 'PRP')),\n",
       "   (('suspect', 'JJ'), 'cop', ('is', 'VBZ')),\n",
       "   (('suspect', 'JJ'), 'neg', ('not', 'RB')),\n",
       "   (('suspect', 'JJ'), 'det', ('a', 'DT')),\n",
       "   (('suspect', 'JJ'), 'advmod', ('anymore', 'RB')),\n",
       "   (('suspect', 'JJ'), 'punct', ('.', '.')),\n",
       "   (('suspect', 'JJ'), 'punct', (\"''\", \"''\"))]],\n",
       " [[(('flew', 'VBD'), 'nsubj', ('They', 'PRP')),\n",
       "   (('flew', 'VBD'), 'nmod', ('nest', 'NN')),\n",
       "   (('nest', 'NN'), 'case', ('out', 'RB')),\n",
       "   (('nest', 'NN'), 'case', ('of', 'IN')),\n",
       "   (('nest', 'NN'), 'det', ('the', 'DT')),\n",
       "   (('flew', 'VBD'), 'nmod', ('groups', 'NNS')),\n",
       "   (('groups', 'NNS'), 'case', ('in', 'IN')),\n",
       "   (('flew', 'VBD'), 'punct', ('.', '.'))],\n",
       "  [(('flew', 'VBD'), 'nsubj', ('They', 'PRP')),\n",
       "   (('flew', 'VBD'), 'nmod', ('nest', 'NN')),\n",
       "   (('nest', 'NN'), 'case', ('into', 'IN')),\n",
       "   (('nest', 'NN'), 'det', ('the', 'DT')),\n",
       "   (('flew', 'VBD'), 'advmod', ('together', 'RB')),\n",
       "   (('flew', 'VBD'), 'punct', ('.', '.'))]],\n",
       " [[(('playing', 'VBG'), 'nsubj', ('woman', 'NN')),\n",
       "   (('woman', 'NN'), 'det', ('The', 'DT')),\n",
       "   (('playing', 'VBG'), 'aux', ('is', 'VBZ')),\n",
       "   (('playing', 'VBG'), 'dobj', ('violin', 'NN')),\n",
       "   (('violin', 'NN'), 'det', ('the', 'DT')),\n",
       "   (('playing', 'VBG'), 'punct', ('.', '.'))],\n",
       "  [(('enjoys', 'VBZ'), 'nsubj', ('lady', 'NN')),\n",
       "   (('lady', 'NN'), 'det', ('The', 'DT')),\n",
       "   (('lady', 'NN'), 'amod', ('young', 'JJ')),\n",
       "   (('enjoys', 'VBZ'), 'xcomp', ('listening', 'VBG')),\n",
       "   (('listening', 'VBG'), 'nmod', ('guitar', 'NN')),\n",
       "   (('guitar', 'NN'), 'case', ('to', 'TO')),\n",
       "   (('guitar', 'NN'), 'det', ('the', 'DT')),\n",
       "   (('enjoys', 'VBZ'), 'punct', ('.', '.'))]],\n",
       " [[(('went', 'VBD'), 'nsubj', ('John', 'NNP')),\n",
       "   (('went', 'VBD'), 'dobj', ('horse', 'NN')),\n",
       "   (('went', 'VBD'), 'xcomp', ('riding', 'VBG')),\n",
       "   (('riding', 'VBG'), 'advmod', ('back', 'RB')),\n",
       "   (('riding', 'VBG'), 'nmod', ('dawn', 'NN')),\n",
       "   (('dawn', 'NN'), 'case', ('at', 'IN')),\n",
       "   (('riding', 'VBG'), 'nmod', ('group', 'NN')),\n",
       "   (('group', 'NN'), 'case', ('with', 'IN')),\n",
       "   (('group', 'NN'), 'det', ('a', 'DT')),\n",
       "   (('group', 'NN'), 'amod', ('whole', 'JJ')),\n",
       "   (('group', 'NN'), 'nmod', ('friends', 'NNS')),\n",
       "   (('friends', 'NNS'), 'case', ('of', 'IN')),\n",
       "   (('went', 'VBD'), 'punct', ('.', '.'))],\n",
       "  [(('view', 'NN'), 'nsubj', ('Sunrise', 'NNP')),\n",
       "   (('Sunrise', 'NNP'), 'nmod', ('dawn', 'NN')),\n",
       "   (('dawn', 'NN'), 'case', ('at', 'IN')),\n",
       "   (('view', 'NN'), 'cop', ('is', 'VBZ')),\n",
       "   (('view', 'NN'), 'det', ('a', 'DT')),\n",
       "   (('view', 'NN'), 'amod', ('magnificent', 'JJ')),\n",
       "   (('view', 'NN'), 'acl', ('take', 'VB')),\n",
       "   (('take', 'VB'), 'mark', ('to', 'TO')),\n",
       "   (('take', 'VB'), 'compound:prt', ('in', 'RP')),\n",
       "   (('take', 'VB'), 'advcl', ('wake', 'VBP')),\n",
       "   (('wake', 'VBP'), 'mark', ('if', 'IN')),\n",
       "   (('wake', 'VBP'), 'nsubj', ('you', 'PRP')),\n",
       "   (('wake', 'VBP'), 'advmod', ('up', 'RB')),\n",
       "   (('wake', 'VBP'), 'advmod', ('enough', 'JJ')),\n",
       "   (('enough', 'JJ'), 'advmod', ('early', 'RB')),\n",
       "   (('enough', 'JJ'), 'nmod', ('it', 'PRP')),\n",
       "   (('it', 'PRP'), 'case', ('for', 'IN')),\n",
       "   (('view', 'NN'), 'punct', ('.', '.'))]]]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences = [\n",
    "        list(map(lambda p: list(next(parser.raw_parse(p)).triples()), sentence_pair.strip().split('\\t')))\n",
    "        for sentence_pair in re.compile('id[\\d]\\t').split(corpus) \n",
    "        if sentence_pair != ''\n",
    "]\n",
    "sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate the Jaccard distance among the pairs of sentences\n",
    "We calculate the distance between the pairs of sentences to give a measure of their similarity and we contrast it with the golden ratio which is a real measure of the similarity from 0 to 5 being 0 phrases that are completely different and 5 phrases that mean exactly the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jaccard distance is 1.0 and its real golden ratio is 0\n",
      "Jaccard distance is 1.0 and its real golden ratio is 1\n",
      "Jaccard distance is 1.0 and its real golden ratio is 2\n",
      "Jaccard distance is 0.6 and its real golden ratio is 3\n",
      "Jaccard distance is 1.0 and its real golden ratio is 4\n",
      "Jaccard distance is 0.9666666666666667 and its real golden ratio is 5\n"
     ]
    }
   ],
   "source": [
    "jaccard_distances = [jaccard_distance(*map(lambda s: set(s), sentence_pairs)) for sentence_pairs in sentences]\n",
    "golden_ratios = [0, 1, 2, 3, 4, 5]\n",
    "for golden_ratio, jaccard_distance in zip(golden_ratios, jaccard_distances):\n",
    "    print(f'Jaccard distance is {jaccard_distance} and its real golden ratio is {golden_ratio}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pearson Linear Correlation Cofficient\n",
    "Finally we get a measure of the correlation among those values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.18798210894408277"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pearsonr(jaccard_distances, golden_ratios)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To recap\n",
    "It is useful to use NEs but it must be together with other techniques so we can extract useful information. Using NEs alone we get a collection of relations but also using semantic matching and coreference resolution for example will obtain a better result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
