{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mandatory Exercise - Session 5\n",
    "\n",
    "### Students: Nafis Banirazi & Jan Carbonell\n",
    "\n",
    "### Lab Objective:\n",
    "The Objective of this lab is to categorize the given pairs, print their most frequent WordNet synset, their corresponding least common subsumer (LCS) and their similarity using the following functions:\n",
    "\n",
    "- Path Similarity\n",
    "- Leacock-Chodorow Similarity\n",
    "- Wu-Palmer Similarity\n",
    "- Lin Similarity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial imports. Could also be done in the PC\n",
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import itertools\n",
    "\n",
    "#additional set of imports\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.corpus import wordnet_ic\n",
    "\n",
    "\n",
    "#given set of pairs\n",
    "pairs = [('the', 'DT'), ('man', 'NN'), ('swim', 'VB'), \\\n",
    "         ('with', 'PR'), ('a', 'DT'), ('girl', 'NN'), \\\n",
    "         ('and', 'CC'), ('a', 'DT'), ('boy', 'NN'), \\\n",
    "         ('whilst', 'PR'), ('the', 'DT'), ('woman', 'NN'), \\\n",
    "         ('walk', 'VB')]\n",
    "n = {}\n",
    "v = {}\n",
    "aux = {}\n",
    "freq = []\n",
    "lcs = []\n",
    "definition = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, for each pair, we will search for their most frequent WordNet sysnset. In the documentation we can find that there are also adjectives and adverbs listed as options but are not used in this given set of pairs. Listing it as a reference: https://wordnet.princeton.edu/documentation/wn1wn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "man ['noun', Synset('man.n.01')]\n",
      "girl ['noun', Synset('girl.n.01')]\n",
      "boy ['noun', Synset('male_child.n.01')]\n",
      "woman ['noun', Synset('woman.n.01')]\n",
      "swim ['verb', Synset('swim.v.01')]\n",
      "walk ['verb', Synset('walk.v.01')]\n"
     ]
    }
   ],
   "source": [
    "for e in pairs:\n",
    "    if e[0] not in n and e[0] not in v:\n",
    "        if e[1] == 'NN':\n",
    "            n[e[0]] = ['noun']\n",
    "            n[e[0]] += [wn.synset(e[0]+'.n.01')]\n",
    "        elif e[1] == 'VB':\n",
    "            v[e[0]] = ['verb']\n",
    "            v[e[0]] += [wn.synset(e[0]+'.v.01')]\n",
    "            \n",
    "#verification that it is properly stored\n",
    "for keys,values in n.items():\n",
    "    print(keys, values)\n",
    "    \n",
    "for keys,values in v.items():\n",
    "    print(keys, values)\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each of the pairs that was found to be on WordNet, we now get their corresponding least commmon subsumer. That is the most specific common ancestor (hypernym) of two concepts found in a given ontology. For example, the LCS of moose and kangaroo in WordNet is mammal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('man', 'noun', Synset('man.n.01')), ('girl', 'noun', Synset('girl.n.01')), ('boy', 'noun', Synset('male_child.n.01')), ('woman', 'noun', Synset('woman.n.01')), ('swim', 'verb', Synset('swim.v.01')), ('walk', 'verb', Synset('walk.v.01'))]\n",
      "man\n"
     ]
    }
   ],
   "source": [
    "for key in n:\n",
    "    if key not in freq:\n",
    "        freq += [(key, n[key][0], n[key][1])]\n",
    "\n",
    "for key in v:\n",
    "    if key not in freq:\n",
    "        freq += [(key, v[key][0], v[key][1])]\n",
    "\n",
    "print(freq)\n",
    "print(freq[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[Synset('man.n.01')], [Synset('adult.n.01')], [Synset('male.n.02')], [Synset('adult.n.01')], [], []]\n",
      "6\n",
      "[[Synset('adult.n.01')], [Synset('girl.n.01')], [Synset('person.n.01')], [Synset('woman.n.01')], [], []]\n",
      "6\n",
      "[[Synset('male.n.02')], [Synset('person.n.01')], [Synset('male_child.n.01')], [Synset('person.n.01')], [], []]\n",
      "6\n",
      "[[Synset('adult.n.01')], [Synset('woman.n.01')], [Synset('person.n.01')], [Synset('woman.n.01')], [], []]\n",
      "6\n",
      "[[], [], [], [], [Synset('swim.v.01')], [Synset('travel.v.01')]]\n",
      "6\n",
      "[[], [], [], [], [Synset('travel.v.01')], [Synset('walk.v.01')]]\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "for key in freq:\n",
    "    row = []\n",
    "    for alt in freq:\n",
    "        row.append(key[2].lowest_common_hypernyms(alt[2]))\n",
    "    lcs.append(row)\n",
    "    \n",
    "for row in lcs:\n",
    "    print(row)\n",
    "    print(len(row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>(man, noun, Synset('man.n.01'))</th>\n",
       "      <th>(girl, noun, Synset('girl.n.01'))</th>\n",
       "      <th>(boy, noun, Synset('male_child.n.01'))</th>\n",
       "      <th>(woman, noun, Synset('woman.n.01'))</th>\n",
       "      <th>(swim, verb, Synset('swim.v.01'))</th>\n",
       "      <th>(walk, verb, Synset('walk.v.01'))</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>(man, noun, Synset('man.n.01'))</th>\n",
       "      <td>[Synset('man.n.01')]</td>\n",
       "      <td>[Synset('adult.n.01')]</td>\n",
       "      <td>[Synset('male.n.02')]</td>\n",
       "      <td>[Synset('adult.n.01')]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(girl, noun, Synset('girl.n.01'))</th>\n",
       "      <td>[Synset('adult.n.01')]</td>\n",
       "      <td>[Synset('girl.n.01')]</td>\n",
       "      <td>[Synset('person.n.01')]</td>\n",
       "      <td>[Synset('woman.n.01')]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(boy, noun, Synset('male_child.n.01'))</th>\n",
       "      <td>[Synset('male.n.02')]</td>\n",
       "      <td>[Synset('person.n.01')]</td>\n",
       "      <td>[Synset('male_child.n.01')]</td>\n",
       "      <td>[Synset('person.n.01')]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(woman, noun, Synset('woman.n.01'))</th>\n",
       "      <td>[Synset('adult.n.01')]</td>\n",
       "      <td>[Synset('woman.n.01')]</td>\n",
       "      <td>[Synset('person.n.01')]</td>\n",
       "      <td>[Synset('woman.n.01')]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(swim, verb, Synset('swim.v.01'))</th>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Synset('swim.v.01')]</td>\n",
       "      <td>[Synset('travel.v.01')]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(walk, verb, Synset('walk.v.01'))</th>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Synset('travel.v.01')]</td>\n",
       "      <td>[Synset('walk.v.01')]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       (man, noun, Synset('man.n.01'))  \\\n",
       "(man, noun, Synset('man.n.01'))                   [Synset('man.n.01')]   \n",
       "(girl, noun, Synset('girl.n.01'))               [Synset('adult.n.01')]   \n",
       "(boy, noun, Synset('male_child.n.01'))           [Synset('male.n.02')]   \n",
       "(woman, noun, Synset('woman.n.01'))             [Synset('adult.n.01')]   \n",
       "(swim, verb, Synset('swim.v.01'))                                   []   \n",
       "(walk, verb, Synset('walk.v.01'))                                   []   \n",
       "\n",
       "                                       (girl, noun, Synset('girl.n.01'))  \\\n",
       "(man, noun, Synset('man.n.01'))                   [Synset('adult.n.01')]   \n",
       "(girl, noun, Synset('girl.n.01'))                  [Synset('girl.n.01')]   \n",
       "(boy, noun, Synset('male_child.n.01'))           [Synset('person.n.01')]   \n",
       "(woman, noun, Synset('woman.n.01'))               [Synset('woman.n.01')]   \n",
       "(swim, verb, Synset('swim.v.01'))                                     []   \n",
       "(walk, verb, Synset('walk.v.01'))                                     []   \n",
       "\n",
       "                                       (boy, noun, Synset('male_child.n.01'))  \\\n",
       "(man, noun, Synset('man.n.01'))                         [Synset('male.n.02')]   \n",
       "(girl, noun, Synset('girl.n.01'))                     [Synset('person.n.01')]   \n",
       "(boy, noun, Synset('male_child.n.01'))            [Synset('male_child.n.01')]   \n",
       "(woman, noun, Synset('woman.n.01'))                   [Synset('person.n.01')]   \n",
       "(swim, verb, Synset('swim.v.01'))                                          []   \n",
       "(walk, verb, Synset('walk.v.01'))                                          []   \n",
       "\n",
       "                                       (woman, noun, Synset('woman.n.01'))  \\\n",
       "(man, noun, Synset('man.n.01'))                     [Synset('adult.n.01')]   \n",
       "(girl, noun, Synset('girl.n.01'))                   [Synset('woman.n.01')]   \n",
       "(boy, noun, Synset('male_child.n.01'))             [Synset('person.n.01')]   \n",
       "(woman, noun, Synset('woman.n.01'))                 [Synset('woman.n.01')]   \n",
       "(swim, verb, Synset('swim.v.01'))                                       []   \n",
       "(walk, verb, Synset('walk.v.01'))                                       []   \n",
       "\n",
       "                                       (swim, verb, Synset('swim.v.01'))  \\\n",
       "(man, noun, Synset('man.n.01'))                                       []   \n",
       "(girl, noun, Synset('girl.n.01'))                                     []   \n",
       "(boy, noun, Synset('male_child.n.01'))                                []   \n",
       "(woman, noun, Synset('woman.n.01'))                                   []   \n",
       "(swim, verb, Synset('swim.v.01'))                  [Synset('swim.v.01')]   \n",
       "(walk, verb, Synset('walk.v.01'))                [Synset('travel.v.01')]   \n",
       "\n",
       "                                       (walk, verb, Synset('walk.v.01'))  \n",
       "(man, noun, Synset('man.n.01'))                                       []  \n",
       "(girl, noun, Synset('girl.n.01'))                                     []  \n",
       "(boy, noun, Synset('male_child.n.01'))                                []  \n",
       "(woman, noun, Synset('woman.n.01'))                                   []  \n",
       "(swim, verb, Synset('swim.v.01'))                [Synset('travel.v.01')]  \n",
       "(walk, verb, Synset('walk.v.01'))                  [Synset('walk.v.01')]  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(freq))\n",
    "lcs_np = np.array(lcs)\n",
    "pd.DataFrame(lcs_np, columns=freq, index=freq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then plot the results, not only to better visualize the specific x and y coordinates that we have obtained and store but also to connect the dots and evaluate the overall increase in performance and benchmarking against the other models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adding the necessary packages for plotting\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#preparing and plotting the accuracy graph\n",
    "x = train_stop\n",
    "plt.figure()\n",
    "plt.plot(x, accuracy['HMM'], label='HMM')\n",
    "plt.plot(x, accuracy['TnT'], label='TnT')\n",
    "plt.plot(x, accuracy['PER'], label='PER')\n",
    "plt.plot(x, accuracy['CRF'], label='CRF')\n",
    "\n",
    "#adding the legend showing the plot\n",
    "plt.xlabel('Number of Sentences')\n",
    "plt.ylabel('Model Accuracy')\n",
    "plt.title('Part Of Speech Models')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Which model would you select?</b> Justify the answer.\n",
    "\n",
    "Based on the initial graph, both CRF and PER seem like the better performing algorithms. If we could only make a decision based on this data, we would pick the Perceptron model.\n",
    "\n",
    "In order to pick the best overall model, another relevant measure is the speed of the system. Because of this, we also have implemented a timer in between each of the models and will plot it accordingly to figure out which algorithms were more effective. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preparing and plotting the accuracy graph\n",
    "x = train_stop\n",
    "plt.figure()\n",
    "plt.plot(x, time['HMM'], label='HMM')\n",
    "plt.plot(x, time['TnT'], label='TnT')\n",
    "plt.plot(x, time['PER'], label='PER')\n",
    "plt.plot(x, time['CRF'], label='CRF')\n",
    "\n",
    "#adding the legend showing the plot\n",
    "plt.xlabel('Number of Sentences')\n",
    "plt.ylabel('Model Execution Time')\n",
    "plt.title('Part Of Speech Models')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, PER seems to be the most effective -accuracy wise- and second most time efficient algorithm. After having performed this additional execution time analysis <b> we are reinsured in our conclusion to pick the Perceptron Model.</b> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions\n",
    "Over the development of this lab, we have implemented 4 different POS Models, tested them with different segments of the treebank corpus and trained them with another set of segments. From those results, we have plotted their performanced based on accuracy and execution time and have selected the best performing model for this specific case, which happened to be the Perceptron Model. \n",
    "\n",
    "Another thing to highlight is that the HiddenMarkovModel looks really efficient timewise. It is likely that its just not in the desired set of conditions regarding the amount of data to perform correctly. \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
