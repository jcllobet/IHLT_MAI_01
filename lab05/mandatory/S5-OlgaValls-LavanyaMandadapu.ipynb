{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mandatory Exercise - Session 5\n",
    "### Olga Valls & Lavanya Mandadapu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We import the packages that we need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.corpus import wordnet_ic\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given the following (lemma, category) <b>pairs</b>:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs = [('the', 'DT'), ('man', 'NN'), ('swim', 'VB'), ('with', 'PR'), ('a', 'DT'), ('girl', 'NN'), ('and', 'CC'), ('a', 'DT'), ('boy', 'NN'), ('whilst', 'PR'), ('the', 'DT'), ('woman', 'NN'), ('walk', 'VB')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We select the words of the pairs where the <b>POS tag</b> is NN (<u>noun</u>) or VB (<u>verb</u>), so that we can create an array for nouns and an array for verbs and store the the synsets of those words (nouns/verbs)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "nouns = []\n",
    "verbs = []\n",
    "\n",
    "for p in pairs:\n",
    "    if p[1][0] == 'N':\n",
    "        nouns.append(p[0])\n",
    "    elif p[1][0] == 'V':\n",
    "        verbs.append(p[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create:\n",
    "- list \"types\" for the different types of POS tags that we will use (nouns and verbs)\n",
    "- diccionary \"diccio\", so that when we read nouns/verbs from the corresponding array we can add n/v to the synsets' command, to get the synsets for that word.\n",
    "- dictionary \"diccio_synsets\", so that when we create the common array of most frequent Wordnet synsets of nouns and verbs, we can also store each noun and each verb, in his corresponding array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "types = ['n', 'v']\n",
    "diccio = {'n': nouns, 'v': verbs}\n",
    "diccio_synsets = {'n': [], 'v': []}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Most frequent WordNet synsets\n",
    "For each type of POS tag (noun/verb), we access to the synset of each element of his corresponding array.<br>\n",
    "For each lemma, we get the first one of the output list of synsets, which is the <u>most frequent</u>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n: ['man', 'girl', 'boy', 'woman'] \n",
      "Most frequent man: Synset('man.n.01')\n",
      "Most frequent girl: Synset('girl.n.01')\n",
      "Most frequent boy: Synset('male_child.n.01')\n",
      "Most frequent woman: Synset('woman.n.01')\n",
      "v: ['swim', 'walk'] \n",
      "Most frequent swim: Synset('swim.v.01')\n",
      "Most frequent walk: Synset('walk.v.01')\n"
     ]
    }
   ],
   "source": [
    "freq_synsets = []\n",
    "for t in types:\n",
    "    print('{}: {} '.format(t,diccio[t]))\n",
    "    for x in diccio[t]:\n",
    "        x_synsets = wn.synsets(x, t)\n",
    "        freq_synsets.append(x_synsets[0])\n",
    "        diccio_synsets[t].append(x_synsets[0])\n",
    "        print('Most frequent {}: {}'.format(x, x_synsets[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Least Common Subsumer (LCS)\n",
    "For all the synsets in the list of most frequent WordNet synsets, we search for the Least Common Subsummer (LCS) for each pair of synsets.<br>\n",
    "It's computed with the Wordnet's method lowest_common_hypernyms(), which is used to locate the lowest single hypernym that is shared by two given synsets.<br>\n",
    "<i>http://www.nltk.org/howto/wordnet_lch.html</i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "llcs = []\n",
    "for i in range(len(freq_synsets)):\n",
    "    rows = []\n",
    "    for j in range(len(freq_synsets)):\n",
    "        rows.append(freq_synsets[i].lowest_common_hypernyms(freq_synsets[j]))\n",
    "    llcs.append(rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>LCS</b> among each pair of lemmas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Synset('man.n.01')</th>\n",
       "      <th>Synset('girl.n.01')</th>\n",
       "      <th>Synset('male_child.n.01')</th>\n",
       "      <th>Synset('woman.n.01')</th>\n",
       "      <th>Synset('swim.v.01')</th>\n",
       "      <th>Synset('walk.v.01')</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Synset('man.n.01')</th>\n",
       "      <td>[Synset('man.n.01')]</td>\n",
       "      <td>[Synset('adult.n.01')]</td>\n",
       "      <td>[Synset('male.n.02')]</td>\n",
       "      <td>[Synset('adult.n.01')]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Synset('girl.n.01')</th>\n",
       "      <td>[Synset('adult.n.01')]</td>\n",
       "      <td>[Synset('girl.n.01')]</td>\n",
       "      <td>[Synset('person.n.01')]</td>\n",
       "      <td>[Synset('woman.n.01')]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Synset('male_child.n.01')</th>\n",
       "      <td>[Synset('male.n.02')]</td>\n",
       "      <td>[Synset('person.n.01')]</td>\n",
       "      <td>[Synset('male_child.n.01')]</td>\n",
       "      <td>[Synset('person.n.01')]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Synset('woman.n.01')</th>\n",
       "      <td>[Synset('adult.n.01')]</td>\n",
       "      <td>[Synset('woman.n.01')]</td>\n",
       "      <td>[Synset('person.n.01')]</td>\n",
       "      <td>[Synset('woman.n.01')]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Synset('swim.v.01')</th>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Synset('swim.v.01')]</td>\n",
       "      <td>[Synset('travel.v.01')]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Synset('walk.v.01')</th>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Synset('travel.v.01')]</td>\n",
       "      <td>[Synset('walk.v.01')]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               Synset('man.n.01')      Synset('girl.n.01')  \\\n",
       "Synset('man.n.01')           [Synset('man.n.01')]   [Synset('adult.n.01')]   \n",
       "Synset('girl.n.01')        [Synset('adult.n.01')]    [Synset('girl.n.01')]   \n",
       "Synset('male_child.n.01')   [Synset('male.n.02')]  [Synset('person.n.01')]   \n",
       "Synset('woman.n.01')       [Synset('adult.n.01')]   [Synset('woman.n.01')]   \n",
       "Synset('swim.v.01')                            []                       []   \n",
       "Synset('walk.v.01')                            []                       []   \n",
       "\n",
       "                             Synset('male_child.n.01')  \\\n",
       "Synset('man.n.01')               [Synset('male.n.02')]   \n",
       "Synset('girl.n.01')            [Synset('person.n.01')]   \n",
       "Synset('male_child.n.01')  [Synset('male_child.n.01')]   \n",
       "Synset('woman.n.01')           [Synset('person.n.01')]   \n",
       "Synset('swim.v.01')                                 []   \n",
       "Synset('walk.v.01')                                 []   \n",
       "\n",
       "                              Synset('woman.n.01')      Synset('swim.v.01')  \\\n",
       "Synset('man.n.01')          [Synset('adult.n.01')]                       []   \n",
       "Synset('girl.n.01')         [Synset('woman.n.01')]                       []   \n",
       "Synset('male_child.n.01')  [Synset('person.n.01')]                       []   \n",
       "Synset('woman.n.01')        [Synset('woman.n.01')]                       []   \n",
       "Synset('swim.v.01')                             []    [Synset('swim.v.01')]   \n",
       "Synset('walk.v.01')                             []  [Synset('travel.v.01')]   \n",
       "\n",
       "                               Synset('walk.v.01')  \n",
       "Synset('man.n.01')                              []  \n",
       "Synset('girl.n.01')                             []  \n",
       "Synset('male_child.n.01')                       []  \n",
       "Synset('woman.n.01')                            []  \n",
       "Synset('swim.v.01')        [Synset('travel.v.01')]  \n",
       "Synset('walk.v.01')          [Synset('walk.v.01')]  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llcs_np = np.array(llcs)\n",
    "pd.DataFrame(llcs_np, columns=freq_synsets, index=freq_synsets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are no Least Common Subsumer for any noun vs any verb, as they belong to different categories.\n",
    "\n",
    "The two verbs are related with the lemma travel, which defines movement; walk is traveling on foot, and swimming is traveling in an aquous environment.\n",
    "\n",
    "The four nouns have different relationships, the common one would be person, which would belong to a higher category.<br>\n",
    "As an example we can see that man and woman are adults, girl is a woman but not an adult. Boy is a male, a male_child, which means that he is not an adult as man is."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Similarity Value\n",
    "We separate nouns and verbs to compute similarities among each category.<br>\n",
    "For each of the Similarities that we want to compute, we create a list where we will store a list of similarities of nouns and a list of similarities of verbs.\n",
    "\n",
    "For the Lin Similarity we also need to compute the Information Content (IC) value, which load an information content file from the wordnet_ic corpus.\n",
    "\n",
    "Comparing a synset with itself will return 1. That means, that if some similarity result is higher than 1 we will have to normalise the values between 0 and 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "brown_ic = wordnet_ic.ic('ic-brown.dat')\n",
    "\n",
    "sim_path_all = []\n",
    "sim_lch_all = []\n",
    "sim_wup_all = []\n",
    "sim_lin_all = []\n",
    "\n",
    "for x, t in enumerate(types):\n",
    "    sim_path = []\n",
    "    sim_lch = []\n",
    "    sim_wup = []\n",
    "    sim_lin = []\n",
    "    for i in range(len(diccio_synsets[t])):\n",
    "        rows_path = []\n",
    "        rows_lch = []\n",
    "        rows_wup = []\n",
    "        rows_lin = []\n",
    "        for j in range(len(diccio_synsets[t])):\n",
    "            rows_path.append(diccio_synsets[t][i].path_similarity(diccio_synsets[t][j]))\n",
    "            rows_lch.append(diccio_synsets[t][i].lch_similarity(diccio_synsets[t][j]))\n",
    "            rows_wup.append(diccio_synsets[t][i].wup_similarity(diccio_synsets[t][j]))\n",
    "            rows_lin.append(diccio_synsets[t][i].lin_similarity(diccio_synsets[t][j], brown_ic))\n",
    "        sim_path.append(rows_path)\n",
    "        sim_lch.append(rows_lch)\n",
    "        sim_wup.append(rows_wup)\n",
    "        sim_lin.append(rows_lin)\n",
    "    sim_path_all.append(sim_path)\n",
    "    sim_lch_all.append(sim_lch)\n",
    "    sim_wup_all.append(sim_wup)\n",
    "    sim_lin_all.append(sim_lin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Path Similarity\n",
    "<i>Returns a score denoting how similar two word senses are, based on the shortest path that connects the senses in the is-a (hypernym/hypnoym) taxonomy. The score is in the range 0 to 1. By default, there is now a fake root node added to verbs so for cases where previously a path could not be found---and None was returned---it should return a value. The old behavior can be achieved by setting simulate_root to be False. A score of 1 represents identity i.e. comparing a sense with itself will return 1.<br>\n",
    "synset1.path_similarity(synset2)</i>\n",
    "\n",
    "Sim(s1, s2) = 1 / 1+SPL(s1,s2) ,\n",
    "\n",
    "<i>where SPL(s1,s2) = Shortest Path Length from s1 to s2</i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u>Path Similarity for nouns</u>:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Synset('man.n.01')</th>\n",
       "      <th>Synset('girl.n.01')</th>\n",
       "      <th>Synset('male_child.n.01')</th>\n",
       "      <th>Synset('woman.n.01')</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Synset('man.n.01')</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Synset('girl.n.01')</th>\n",
       "      <td>0.250000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Synset('male_child.n.01')</th>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Synset('woman.n.01')</th>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Synset('man.n.01')  Synset('girl.n.01')  \\\n",
       "Synset('man.n.01')                   1.000000             0.250000   \n",
       "Synset('girl.n.01')                  0.250000             1.000000   \n",
       "Synset('male_child.n.01')            0.333333             0.166667   \n",
       "Synset('woman.n.01')                 0.333333             0.500000   \n",
       "\n",
       "                           Synset('male_child.n.01')  Synset('woman.n.01')  \n",
       "Synset('man.n.01')                          0.333333              0.333333  \n",
       "Synset('girl.n.01')                         0.166667              0.500000  \n",
       "Synset('male_child.n.01')                   1.000000              0.200000  \n",
       "Synset('woman.n.01')                        0.200000              1.000000  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_n_np = np.array(sim_path_all[0])\n",
    "pd.DataFrame(path_n_np, columns=diccio_synsets['n'], index=diccio_synsets['n'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Higher values: man/boy and man/woman: 0.333333<br>\n",
    "Lower values: girl/boy: 0.166667"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u>Path Similarity for verbs</u>:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-58c8e3bb4252>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpath_v_np\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msim_path_all\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mlch_n_np\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msim_lch_all\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_v_np\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdiccio_synsets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'v'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdiccio_synsets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'v'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlch_n_np\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdiccio_synsets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'n'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdiccio_synsets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'n'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "path_v_np = np.array(sim_path_all[1])\n",
    "pd.DataFrame(path_v_np, columns=diccio_synsets['v'], index=diccio_synsets['v'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Leacock-Chodorow Similarity\n",
    "<i>Returns a score denoting how similar two word senses are, based on the shortest path that connects the senses (as above) and the maximum depth of the taxonomy in which the senses occur. The relationship is given as -log(p/2d) where p is the shortest path length and d the taxonomy depth.\n",
    "synset1.lch_similarity(synset2)</i>\n",
    "\n",
    "Sim(s1, s2) = −log(SPL(s1,s2)/2*MaxDepth) ,\n",
    "\n",
    "<i>where depth(s) = depth of s in the ontology<br>MaxDepth = maxs∈WN depth(s)</i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u>Leacock-Chodorow Similarity for nouns</u>:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Synset('man.n.01')</th>\n",
       "      <th>Synset('girl.n.01')</th>\n",
       "      <th>Synset('male_child.n.01')</th>\n",
       "      <th>Synset('woman.n.01')</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Synset('man.n.01')</th>\n",
       "      <td>3.637586</td>\n",
       "      <td>2.251292</td>\n",
       "      <td>2.538974</td>\n",
       "      <td>2.538974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Synset('girl.n.01')</th>\n",
       "      <td>2.251292</td>\n",
       "      <td>3.637586</td>\n",
       "      <td>1.845827</td>\n",
       "      <td>2.944439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Synset('male_child.n.01')</th>\n",
       "      <td>2.538974</td>\n",
       "      <td>1.845827</td>\n",
       "      <td>3.637586</td>\n",
       "      <td>2.028148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Synset('woman.n.01')</th>\n",
       "      <td>2.538974</td>\n",
       "      <td>2.944439</td>\n",
       "      <td>2.028148</td>\n",
       "      <td>3.637586</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Synset('man.n.01')  Synset('girl.n.01')  \\\n",
       "Synset('man.n.01')                   3.637586             2.251292   \n",
       "Synset('girl.n.01')                  2.251292             3.637586   \n",
       "Synset('male_child.n.01')            2.538974             1.845827   \n",
       "Synset('woman.n.01')                 2.538974             2.944439   \n",
       "\n",
       "                           Synset('male_child.n.01')  Synset('woman.n.01')  \n",
       "Synset('man.n.01')                          2.538974              2.538974  \n",
       "Synset('girl.n.01')                         1.845827              2.944439  \n",
       "Synset('male_child.n.01')                   3.637586              2.028148  \n",
       "Synset('woman.n.01')                        2.028148              3.637586  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lch_n_np = np.array(sim_lch_all[0])\n",
    "pd.DataFrame(lch_n_np, columns=diccio_synsets['n'], index=diccio_synsets['n'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u>Leacock-Chodorow Similarity for verbs</u>:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Synset('swim.v.01')</th>\n",
       "      <th>Synset('walk.v.01')</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Synset('swim.v.01')</th>\n",
       "      <td>3.258097</td>\n",
       "      <td>2.159484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Synset('walk.v.01')</th>\n",
       "      <td>2.159484</td>\n",
       "      <td>3.258097</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Synset('swim.v.01')  Synset('walk.v.01')\n",
       "Synset('swim.v.01')             3.258097             2.159484\n",
       "Synset('walk.v.01')             2.159484             3.258097"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lch_n_np = np.array(sim_lch_all[1])\n",
    "pd.DataFrame(lch_n_np, columns=diccio_synsets['v'], index=diccio_synsets['v'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we see, the results for Leacock-Chodorow should <b>normalised</b> [0,1]. As we stated before, \"Comparing a synset with itself will return 1\" and it returns 3.258097.\n",
    "\n",
    "We search for the minimun and maximum values of similarity for the nouns, as well as for the verbs (separately). With those values for nouns and verbs we apply the following formula for each element of each correspondant category:<br>\n",
    "<i>x = (x - min) / (max - min)</i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min n: 1.845826690498331\n",
      "max n: 3.6375861597263857\n",
      "min v: 2.159484249353372\n",
      "max v: 3.258096538021482\n"
     ]
    }
   ],
   "source": [
    "lch_norm = []\n",
    "\n",
    "for i, t in enumerate(types):\n",
    "    mins = []\n",
    "    maxs = []\n",
    "    for l in sim_lch_all[i]:\n",
    "        mins.append(min(l))\n",
    "        maxs.append(max(l))\n",
    "    minim = min(mins)\n",
    "    maxim = max(maxs)\n",
    "    print('min {}: {}'.format(t,minim))\n",
    "    print('max {}: {}'.format(t,maxim))\n",
    "\n",
    "    temp = []\n",
    "    for l in sim_lch_all[i]:\n",
    "        x_norm = []\n",
    "        for x in l:\n",
    "            x = (x - minim) / (maxim - minim)\n",
    "            x_norm.append(x)\n",
    "        temp.append(x_norm)\n",
    "    \n",
    "    lch_norm.append(temp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u>Normalised Leacock-Chodorow Similarity for nouns</u>:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Synset('man.n.01')</th>\n",
       "      <th>Synset('girl.n.01')</th>\n",
       "      <th>Synset('male_child.n.01')</th>\n",
       "      <th>Synset('woman.n.01')</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Synset('man.n.01')</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.226294</td>\n",
       "      <td>0.386853</td>\n",
       "      <td>0.386853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Synset('girl.n.01')</th>\n",
       "      <td>0.226294</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.613147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Synset('male_child.n.01')</th>\n",
       "      <td>0.386853</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.101756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Synset('woman.n.01')</th>\n",
       "      <td>0.386853</td>\n",
       "      <td>0.613147</td>\n",
       "      <td>0.101756</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Synset('man.n.01')  Synset('girl.n.01')  \\\n",
       "Synset('man.n.01')                   1.000000             0.226294   \n",
       "Synset('girl.n.01')                  0.226294             1.000000   \n",
       "Synset('male_child.n.01')            0.386853             0.000000   \n",
       "Synset('woman.n.01')                 0.386853             0.613147   \n",
       "\n",
       "                           Synset('male_child.n.01')  Synset('woman.n.01')  \n",
       "Synset('man.n.01')                          0.386853              0.386853  \n",
       "Synset('girl.n.01')                         0.000000              0.613147  \n",
       "Synset('male_child.n.01')                   1.000000              0.101756  \n",
       "Synset('woman.n.01')                        0.101756              1.000000  "
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lch_n_np = np.array(lch_norm[0])\n",
    "pd.DataFrame(lch_n_np, columns=diccio_synsets['n'], index=diccio_synsets['n'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Higher values: girl/woman: 0.613147<br>\n",
    "Lower values: girl/boy: 0.000000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u>Normalised Leacock-Chodorow Similarity for verbs</u>:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Synset('swim.v.01')</th>\n",
       "      <th>Synset('walk.v.01')</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Synset('swim.v.01')</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Synset('walk.v.01')</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Synset('swim.v.01')  Synset('walk.v.01')\n",
       "Synset('swim.v.01')                  1.0                  0.0\n",
       "Synset('walk.v.01')                  0.0                  1.0"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lch_v_np = np.array(lch_norm[1])\n",
    "pd.DataFrame(lch_v_np, columns=diccio_synsets['v'], index=diccio_synsets['v'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Wu-Palmer Similarity\n",
    "Returns a score denoting how similar two word senses are, based on the depth of the two senses in the taxonomy and that of their Least Common Subsumer (most specific ancestor node). Note that at this time the scores given do _not_ always agree with those given by Pedersen's Perl implementation of Wordnet Similarity.\n",
    "<i>ynset1.wup_similarity(synset2)</i>\n",
    "\n",
    "Sim(s1, s2) = 2·depth(LCS(s1,s2)) / (depth(s1)+depth(s2)) ,\n",
    "\n",
    "<i>where LCS(s1,s2) = Lowest Common Subsumer of s1 and s2</i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u>Wu-Palmer Similarity for nouns</u>:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Synset('man.n.01')</th>\n",
       "      <th>Synset('girl.n.01')</th>\n",
       "      <th>Synset('male_child.n.01')</th>\n",
       "      <th>Synset('woman.n.01')</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Synset('man.n.01')</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Synset('girl.n.01')</th>\n",
       "      <td>0.631579</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.631579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Synset('male_child.n.01')</th>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Synset('woman.n.01')</th>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Synset('man.n.01')  Synset('girl.n.01')  \\\n",
       "Synset('man.n.01')                   1.000000             0.631579   \n",
       "Synset('girl.n.01')                  0.631579             1.000000   \n",
       "Synset('male_child.n.01')            0.666667             0.631579   \n",
       "Synset('woman.n.01')                 0.666667             0.947368   \n",
       "\n",
       "                           Synset('male_child.n.01')  Synset('woman.n.01')  \n",
       "Synset('man.n.01')                          0.666667              0.666667  \n",
       "Synset('girl.n.01')                         0.631579              0.631579  \n",
       "Synset('male_child.n.01')                   1.000000              0.666667  \n",
       "Synset('woman.n.01')                        0.666667              1.000000  "
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wup_n_np = np.array(sim_wup_all[0])\n",
    "pd.DataFrame(wup_n_np, columns=diccio_synsets['n'], index=diccio_synsets['n'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Higher values: woman/girl: 0.947368<br>\n",
    "Lower values: girl/man, man/girl, boy/girl, girl/boy, girl/woman: 0.631579"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u>Wu-Palmer Similarity for verbs</u>:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Synset('swim.v.01')</th>\n",
       "      <th>Synset('walk.v.01')</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Synset('swim.v.01')</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Synset('walk.v.01')</th>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Synset('swim.v.01')  Synset('walk.v.01')\n",
       "Synset('swim.v.01')             1.000000             0.333333\n",
       "Synset('walk.v.01')             0.333333             1.000000"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wup_v_np = np.array(sim_wup_all[1])\n",
    "pd.DataFrame(wup_v_np, columns=diccio_synsets['v'], index=diccio_synsets['v'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lin Similarity\n",
    "<i>Returns a score denoting how similar two word senses are, based on the Information Content (IC) of the Least Common Subsumer (most specific ancestor node) and that of the two input Synsets. The relationship is given by the equation 2 * IC(lcs) / (IC(s1) + IC(s2)).\n",
    "synset1.lin_similarity(synset2, ic)</i>\n",
    "\n",
    "Sim(s1,s2) = 2·IC(LCS(s1,s2)) / (IC(s1)+IC(s2)) ,\n",
    "\n",
    "<i>where IC(s) = −log2P(s) = information content of s (from frequencies in a corpus)</i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u>Lin Similarity for nouns</u>:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Synset('man.n.01')</th>\n",
       "      <th>Synset('girl.n.01')</th>\n",
       "      <th>Synset('male_child.n.01')</th>\n",
       "      <th>Synset('woman.n.01')</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Synset('man.n.01')</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.713511</td>\n",
       "      <td>0.729472</td>\n",
       "      <td>0.787084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Synset('girl.n.01')</th>\n",
       "      <td>0.713511</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.292728</td>\n",
       "      <td>0.906780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Synset('male_child.n.01')</th>\n",
       "      <td>0.729472</td>\n",
       "      <td>0.292728</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.318423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Synset('woman.n.01')</th>\n",
       "      <td>0.787084</td>\n",
       "      <td>0.906780</td>\n",
       "      <td>0.318423</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Synset('man.n.01')  Synset('girl.n.01')  \\\n",
       "Synset('man.n.01')                   1.000000             0.713511   \n",
       "Synset('girl.n.01')                  0.713511             1.000000   \n",
       "Synset('male_child.n.01')            0.729472             0.292728   \n",
       "Synset('woman.n.01')                 0.787084             0.906780   \n",
       "\n",
       "                           Synset('male_child.n.01')  Synset('woman.n.01')  \n",
       "Synset('man.n.01')                          0.729472              0.787084  \n",
       "Synset('girl.n.01')                         0.292728              0.906780  \n",
       "Synset('male_child.n.01')                   1.000000              0.318423  \n",
       "Synset('woman.n.01')                        0.318423              1.000000  "
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lin_n_np = np.array(sim_lin_all[0])\n",
    "pd.DataFrame(lin_n_np, columns=diccio_synsets['n'], index=diccio_synsets['n'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Higher values: woman/girl, girl/woman: 0.906780<br>\n",
    "Lower values: boy/girl, girl/boy: 0.292728"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u>Lin Similarity for verbs</u>:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Synset('swim.v.01')</th>\n",
       "      <th>Synset('walk.v.01')</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Synset('swim.v.01')</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.491005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Synset('walk.v.01')</th>\n",
       "      <td>0.491005</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Synset('swim.v.01')  Synset('walk.v.01')\n",
       "Synset('swim.v.01')             1.000000             0.491005\n",
       "Synset('walk.v.01')             0.491005             1.000000"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lin_v_np = np.array(sim_lin_all[1])\n",
    "pd.DataFrame(lin_v_np, columns=diccio_synsets['v'], index=diccio_synsets['v'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What similarity seems better?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Leacock-Chodorow, Wu-Palmer and Lin agree that the higher similarity is for the pair: woman/girl. The highest value is Wu-Palmer with 0.947368.\n",
    "The wierd thing is that, for Wu-Palmer, the pair girl/woman has the lowest value witj 0.631579, which is confusing, as the formula doesn't seem to apply any difference in the order of the synsets that we are computing!!!!!\n",
    "\n",
    "All the methods agree that the lowest value is for the pair girl/boy, and Leacock-Chodorow score the lower one with 0.\n",
    "Wu-Palmer also finds the pair girl/man as one of the lowest values, with 0.631579.\n",
    "\n",
    "The difference between the highest and the lower values for each method are:\n",
    "- Path: 0.333333 - 0.166667 = 0.166667\n",
    "- Leacock-Chodorow: 0.613147 - 0 = 0.613147\n",
    "- Wu-Palmer: 0.947368 - 0.631579 = 0.334221\n",
    "- Lin: 0.906780 - 0.292728 = 0,614052\n",
    "\n",
    "As a <b><u>conclusion</u></b> we would say that:<br>\n",
    "<b>Wu-Palmer</b> is <u>confusing</u> as it gives, as we can see below, a <u>different result</u> for woman/girl than for girl/woman, and both results have a hight weight."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9473684210526315"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wn.synset('woman.n.01').wup_similarity(wn.synset('girl.n.01'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.631578947368421"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wn.synset('girl.n.01').wup_similarity(wn.synset('woman.n.01'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Path</b> and <b>Leacock-Chodorow</b> have a <u>distribution of weights quite similar</u>.<br>\n",
    "However, <b>Lin</b> gives <u>lower</u> weights to <u>differences</u> and <u>higher</u> weights to <u>similarities</u>, and, in our example, it has more different weights than the other methods.\n",
    "\n",
    "So we would choose <b><u>Lin</u></b> method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
