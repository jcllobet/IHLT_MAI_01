{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mandatory Exercise - Session 7\n",
    "\n",
    "### Students: Nafis Banirazi & Jan Carbonell\n",
    "\n",
    "### Lab Objective:\n",
    "The Objective of this lab is toread all the pairs of sentences, compute their similarities using words + Nammed Enntities (NEs) and Jaccard Coefficient and show the results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package maxent_ne_chunker to\n",
      "[nltk_data]     /home/jan/nltk_data...\n",
      "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n",
      "[nltk_data] Downloading package words to /home/jan/nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# initial imports. Could also be done in the PC\n",
    "import nltk\n",
    "import nltk.corpus\n",
    "nltk.download('maxent_ne_chunker')\n",
    "nltk.download('words')\n",
    "\n",
    "#additional set of imports\n",
    "from nltk import pos_tag\n",
    "from nltk.metrics import jaccard_distance\n",
    "from nltk import word_tokenize, pos_tag, ne_chunk\n",
    "from nltk.parse import CoreNLPParser\n",
    "\n",
    "# Core Named-entity tagger as stanford one is deprecated: https://github.com/nltk/nltk/issues/2010\n",
    "tagger = CoreNLPParser(url='http://localhost:9000', tagtype='ner')\n",
    "\n",
    "# launch the server in terminal\n",
    "# java -mx4g -cp \"/home/jan/Downloads/stanford-corenlp-full-2018-10-05/*\" edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9000 -timeout 15000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Mark Pedersen', 'and', 'John Smith', 'are', 'working', 'at', 'Google', 'since', '1994', 'for', '1000', '$', 'per', 'week']\n"
     ]
    }
   ],
   "source": [
    "def get_stanford_named_entity_chunked(sentence):\n",
    "    \"\"\"Given the passed sentence string, returns an array with the chunks (words and named entities) it contains, using Stanford NLP\"\"\"\n",
    "        \n",
    "    # obtain an array with the sentence tokens\n",
    "    tokenized_s = nltk.word_tokenize(sentence)\n",
    "    \n",
    "    # tag and run as a normal word or a named entity (e.g. a person or an organization)\n",
    "    tagged_s = tagger.tag(tokenized_s)\n",
    "    \n",
    "    chunked_sentence = []\n",
    "    last_token = ''\n",
    "    last_tag = ''\n",
    "    \n",
    "    for tagged_token in tagged_s:\n",
    "        \n",
    "        token = tagged_token[0]\n",
    "        tag = tagged_token[1]\n",
    "        \n",
    "        # make normal words have lower case, also discard punctuation marks\n",
    "        if tag == 'O':\n",
    "            if token.isalnum():\n",
    "                chunked_sentence.append(token.lower())\n",
    "         \n",
    "        # keep named entities with the original capitalization\n",
    "        else:\n",
    "            if last_tag == tag:\n",
    "                chunked_sentence[-1] += ' ' + token\n",
    "            else:\n",
    "                chunked_sentence.append(token)\n",
    "        \n",
    "        last_token = token\n",
    "        last_tag = tag\n",
    "    \n",
    "    return chunked_sentence\n",
    "\n",
    "# example: note it does not group the terms of named entities, always 1 by 1. \n",
    "print(get_stanford_named_entity_chunked(\"Mark Pedersen and John Smith are working at Google since 1994 for 1000$ per week.\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  (NE Mark/NNP Pedersen/NNP)\n",
      "  and/CC\n",
      "  (NE John/NNP Smith/NNP)\n",
      "  are/VBP\n",
      "  working/VBG\n",
      "  at/IN\n",
      "  (NE Google/NNP)\n",
      "  since/IN\n",
      "  1994/CD\n",
      "  for/IN\n",
      "  1000/CD\n",
      "  $/$\n",
      "  per/IN\n",
      "  week/NN\n",
      "  ./.)\n"
     ]
    }
   ],
   "source": [
    "def get_ne_chunked(sentence):\n",
    "    \"\"\"Given the passed sentence string, returns an array with the chunks (words and named entities) it contains, using NLTK\"\"\"\n",
    "        \n",
    "    # obtain an array with the sentence tokens\n",
    "    tokenized_s = nltk.word_tokenize(sentence)\n",
    "        \n",
    "    # chunk and tag with NLTK named-entity tagged\n",
    "    x = pos_tag(word_tokenize(sentence))\n",
    "    chunk_tree = ne_chunk(x, binary=True)\n",
    "    \n",
    "    chunked_sentence = []\n",
    "    for chunk in chunk_tree:\n",
    "        \n",
    "        # keep named entities with the original capitalization\n",
    "        if hasattr(chunk, 'label'):\n",
    "            token = ' '.join(term[0] for term in chunk)\n",
    "            chunked_sentence.append(token)\n",
    "            \n",
    "        # make normal words have lower case, also discard puntuaction marks\n",
    "        else:\n",
    "            token = chunk[0]\n",
    "            if token.isalnum():\n",
    "                chunked_sentence.append(token.lower())\n",
    "    \n",
    "    return chunk_tree\n",
    "\n",
    "# example: note that NLTK naming-entity tagger does group the terms of named entities in a single string\n",
    "print(get_ne_chunked(\"Mark Pedersen and John Smith are working at Google since 1994 for 1000$ per week.\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First sentence: \t The bird is bathing in the sink. \n",
      "Second sentence: \t Birdie is washing itself in the water basin.\n",
      " \n",
      "\n",
      "First sentence: \t In May 2010, the troops attempted to invade Kabul. \n",
      "Second sentence: \t The US army invaded Kabul on May 7th last year, 2010.\n",
      " \n",
      "\n",
      "First sentence: \t John said he is considered a witness but not a suspect. \n",
      "Second sentence: \t \"He is not a suspect anymore.\" John said.\n",
      " \n",
      "\n",
      "First sentence: \t They flew out of the nest in groups. \n",
      "Second sentence: \t They flew into the nest together.\n",
      " \n",
      "\n",
      "First sentence: \t The woman is playing the violin. \n",
      "Second sentence: \t The young lady enjoys listening to the guitar.\n",
      " \n",
      "\n",
      "First sentence: \t John went horse back riding at dawn with a whole group of friends. \n",
      "Second sentence: \t Sunrise at dawn is a magnificent view to take in if you wake up early enough for it.\n",
      " \n",
      "\n",
      "\n",
      "['the', 'bird', 'is', 'bathing', 'in', 'the', 'sink']\n",
      "['birdie', 'is', 'washing', 'itself', 'in', 'the', 'water', 'basin']\n",
      "['in', 'May 2010', 'the', 'troops', 'attempted', 'to', 'invade', 'Kabul']\n",
      "['the', 'US', 'army', 'invaded', 'Kabul', 'on', 'May 7th last year , 2010']\n",
      "['John', 'said', 'he', 'is', 'considered', 'a', 'witness', 'but', 'not', 'a', 'suspect']\n",
      "['he', 'is', 'not', 'a', 'suspect', 'anymore', 'John', 'said']\n",
      "['they', 'flew', 'out', 'of', 'the', 'nest', 'in', 'groups']\n",
      "['they', 'flew', 'into', 'the', 'nest', 'together']\n",
      "['the', 'woman', 'is', 'playing', 'the', 'violin']\n",
      "['the', 'young', 'lady', 'enjoys', 'listening', 'to', 'the', 'guitar']\n",
      "['John', 'went', 'horse', 'back', 'riding', 'at', 'dawn', 'with', 'a', 'whole', 'group', 'of', 'friends']\n",
      "['sunrise', 'at', 'dawn', 'is', 'a', 'magnificent', 'view', 'to', 'take', 'in', 'if', 'you', 'wake', 'up', 'early', 'enough', 'for', 'it']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# full path of the corpus file, with that the trial folder containing the input file being in the same directory as the JPN\n",
    "absolute_file_path = os.path.dirname(os.path.abspath(\"__file__\")) + \"//trial//STS.input.txt\"\n",
    "\n",
    "# find all sentence pairs in the document\n",
    "sentence_pairs = []\n",
    "sentence_set_pairs = []\n",
    "with open(absolute_file_path) as f:\n",
    "    lines = f.readlines()\n",
    "    for line in lines:\n",
    "        index, sentence0, sentence1 = line.split(\"\\t\")\n",
    "        sentence_pairs.append((get_stanford_named_entity_chunked(sentence0), get_stanford_named_entity_chunked(sentence1)))\n",
    "        print(\"First sentence: \\t\", sentence0, \"\\nSecond sentence: \\t\", sentence1, \"\\n\")\n",
    "    print()  \n",
    "    \n",
    "# the pairs of sentences are shown\n",
    "for pair in sentence_pairs:\n",
    "    print(pair[0])\n",
    "    print(pair[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Sentence similarity calculation using words and named entities, compared with the gold standard.\n",
    "The pairs of sentences are checked to see how similar they are, using the Jaccard distance: the more words or named entities two sentences share, the more alike they are considered to be. The pairs are shown along with their distance and dissimilarity score (scaled to be comparable with the gold standard one)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unhashable type: 'Tree'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-d5c24350db5b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence_pairs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mpair\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msentence_pairs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0mword_ne_dist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjaccard_distance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpair\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpair\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m     \u001b[0mword_ne_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword_ne_dist\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mword_ne_scores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword_ne_score\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: unhashable type: 'Tree'"
     ]
    }
   ],
   "source": [
    "from nltk.metrics import jaccard_distance\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "# gold standard file path\n",
    "absolute_file_path = os.path.dirname(os.path.abspath(\"__file__\")) + \"//trial//STS.gs.txt\"\n",
    "\n",
    "# get the gold standard scores\n",
    "gold_scores = []\n",
    "with open(absolute_file_path) as f:\n",
    "    lines = f.readlines()\n",
    "    for line in lines:\n",
    "        _, score = line.split(\"\\t\")\n",
    "        gold_scores.append(int(score))\n",
    "        \n",
    "word_ne_scores = []\n",
    "\n",
    "# compute the Jaccard distance to see how similar or different two sentences are\n",
    "for i in range(len(sentence_pairs)):\n",
    "    pair = sentence_pairs[i]\n",
    "    word_ne_dist = jaccard_distance(set(pair[0]), set(pair[1]))\n",
    "    word_ne_score = round(word_ne_dist * 5)\n",
    "    word_ne_scores.append(word_ne_score)\n",
    "    print(\"First sentence words and named entities: \", pair[0], \"\\nSecond sentence words and named entities: \", pair[1], \"\\nWord-and-named-entity-based distance:\", round(word_ne_dist, 3), \"\\nWord-and-named-entity-based dissimilarity score:\", word_ne_score, \"\\nGold standard dissimilarity score:\", gold_scores[i], \"\\n\") \n",
    "\n",
    "# Pearson correlation between the tested and the gold standard scores\n",
    "word_ne_pearson = pearsonr(word_ne_scores, gold_scores)\n",
    "print(\"Pearson correlation between word-and-named-entity-based method and gold standard:\", round(word_ne_pearson[0], 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can observe from the results, the similarities make semantical sense. \n",
    "- Man and girl are connected by adulthood. Same with man and woman\n",
    "- Girl and boy are connected by person\n",
    "- Interestingly enough, Woman and boy are connected by person despite of Man and girl being connected by adulthood. \n",
    "\n",
    "### 3. Similarity Value\n",
    "\n",
    "We now proceed with the implementation of the algorithm. We also initiate an empty list to store the results for each algorithm and initialize the values and minimum results. In order to speed the calculations, we initiate the maximum value of each algorithm outside the loop.\n",
    "\n",
    "The algorithm calculates the results of the 4 algorithms simultaneously, updates the minimum when needed and rounds the value to the nearest three decimals. \n",
    "\n",
    "Regarding the Lin Similarity, we also need to compute the Information Content (IC) value, which loads an IC file from the wordnet_ic corpus.\n",
    "\n",
    "We also initiate the sum values of the matrix, which will be useful to discuss their effectiveness later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "semcor_ic = wordnet_ic.ic('ic-semcor.dat')\n",
    "\n",
    "path, lch, wup, lin = [], [], [], []\n",
    "v1, v2, v3, v4 = 0, 0, 0, 0\n",
    "min1, min2, min3, min4 = 10, 10, 10, 10\n",
    "\n",
    "sum1, sum2, sum3, sum4 = 0, 0, 0, 0\n",
    "\n",
    "#calculating max value of the algorithms outside the loop to preserve them\n",
    "a = wn.synset('dog.n.01')\n",
    "max1 = wn.lch_similarity(a, a)\n",
    "max2 = wn.lch_similarity(a, a)\n",
    "max3 = wn.wup_similarity(a, a)\n",
    "max4 = a.lin_similarity(a, semcor_ic)\n",
    "\n",
    "for key in freq:\n",
    "    \n",
    "    #initializing the rows of the matrices\n",
    "    row1 = []\n",
    "    row2 = []\n",
    "    row3 = []\n",
    "    row4 = []\n",
    "    \n",
    "    for alt in freq:\n",
    "        # adding only if they belong to the same class 'noun' // 'verb'\n",
    "        if key[2] == alt[2]:\n",
    "            \n",
    "            # calculating the result of the algorithm\n",
    "            v1 = wn.path_similarity(key[1], alt[1])\n",
    "            v2 = wn.lch_similarity(key[1], alt[1])\n",
    "            v3 = wn.wup_similarity(key[1], alt[1])\n",
    "            v4 = key[1].lin_similarity(alt[1], semcor_ic)\n",
    "            \n",
    "            # tracking the minimum value in the matrix\n",
    "            if min1 > v1:\n",
    "                min1 = v1\n",
    "            elif min2 > v2:\n",
    "                min2 = v2\n",
    "            elif min3 > v3:\n",
    "                min3 = v3\n",
    "            elif min4 > v4:\n",
    "                min4 = v4\n",
    "                \n",
    "            #updating the total \"value\" of the matrix\n",
    "            sum1 += round(v1,3)\n",
    "            sum2 += round(v2,3)\n",
    "            sum3 += round(v3,3)\n",
    "            sum4 += round(v4,3)\n",
    "            \n",
    "            # rounding it and appending it to row\n",
    "            row1.append(round(v1, 3))\n",
    "            row2.append(round(v2, 3))\n",
    "            row3.append(round(v3, 3))\n",
    "            row4.append(round(v4, 3))\n",
    "            \n",
    "        else:\n",
    "            row1.append(0)\n",
    "            row2.append(0)\n",
    "            row3.append(0)\n",
    "            row4.append(0)\n",
    "    path.append(row1)\n",
    "    lch.append(row2)\n",
    "    wup.append(row3)\n",
    "    lin.append(row4)\n",
    "    \n",
    "#verification that it is properly stored    \n",
    "print(path)\n",
    "print(sum1)\n",
    "print('\\n')\n",
    "print(lch)\n",
    "print(sum2)\n",
    "print('\\n')\n",
    "print(wup)\n",
    "print(sum3)\n",
    "print('\\n')\n",
    "print(lin)\n",
    "print(sum4)\n",
    "print('\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see from our rudimentary prints, the Leacock-Chodorow Similarity could use some normalization so that we can compare its efficiency to the other algorithms. Since we have already calculated the max and the previous loop is finished, the value of min is also final and we can apply the normalization as follows:\n",
    "\n",
    "<i>x' = (x - min_lch) / (max_lch - min_lch)</i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#restart the value of the sum since we normalize\n",
    "sum2 = 0\n",
    "\n",
    "for row in range(len(lch)):\n",
    "    for e in range(len(lch[row])):\n",
    "        if lch[row][e] == 0:\n",
    "            pass\n",
    "        else:\n",
    "            lch[row][e] = round((lch[row][e]-min2)/(max2-min2), 3)\n",
    "            sum2 += round(lch[row][e],3)\n",
    "            \n",
    "print(sum2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>What similarity seems better?</b>\n",
    "\n",
    "First we proceed with each of the individual plots. One think to verify as we run to the matrices is the simetric value of the data. If the values diverge in each side of the diagonal, it already is a big indication of the inestability of the algorithm since the order of the products should not alter the result. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_np = np.array(path)\n",
    "pd.DataFrame(path_np, columns = label, index= label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another thing to have in mind for the Leacock-Chodorow Similarity is that we have normalized it with the minimum value in our matrix, and not necessarly the min *possible* value.  This means that normalization could change if we were to calculate more broad results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lch_np = np.array(lch)\n",
    "pd.DataFrame(lch_np, columns = label, index= label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wup_np = np.array(wup)\n",
    "pd.DataFrame(wup_np, columns = label, index= label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lin_np = np.array(lin)\n",
    "pd.DataFrame(lin_np, columns = label, index= label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To proceed with the discussion of the efectiveness, we now have two tools, the sum of the elements of each of the matrix and the determinants. However, the determinants are not relevant in order to measure the effectiveness in the algorithm. They add and subtract values to calculate the space of the matrix and this is not what we want when evaluating the accuracy of each individual value. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "det_path = round(np.linalg.det(path_np),3)\n",
    "det_lch = round(np.linalg.det(lch_np),3)\n",
    "det_wup = round(np.linalg.det(wup_np),3)\n",
    "det_lin = round(np.linalg.det(lin_np),3)\n",
    "diff_path = 0.5 - min1\n",
    "diff_lch = 0.613 - 0.102\n",
    "diff_wup = 0.947 - min3\n",
    "diff_lin = 0.882 - min4\n",
    "\n",
    "# Path Similarity\n",
    "print('sum of values:', round(sum1,3))\n",
    "print('determinant:', det_path)  \n",
    "print('difference in local max-min:', round(diff_path,3), '\\n')\n",
    "\n",
    "# Leacock-Chodorow Similarity\n",
    "print('sum of values:', round(sum2,3))\n",
    "print('determinant:', det_lch)  \n",
    "print('difference in local max-min:', round(diff_lch,3), '\\n')\n",
    "\n",
    "# Wu-Palmer Similarity\n",
    "print('sum of values:', round(sum3,3))\n",
    "print('determinant:', det_wup)  \n",
    "print('difference in local max-min:', round(diff_wup,3), '\\n')\n",
    "      \n",
    "#Lin Similarity:\n",
    "print('sum of values:', round(sum4,3))\n",
    "print('determinant:', det_lin)  \n",
    "print('difference in local max-min:', round(diff_lin, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Besides the sum of values, determinants and difference in local maximum and minimum, we must go back to the basics. In the leacock-similarity matrix, we can see that we have **mistakenly overnormalized the value of the comparison to equal verbs to 0.788**. This is likely due to the difference in the algorithm calculation and it is one of the inconveniences of the normalization. However, due to this very fact, the **normalized would be unsuitable if we were to have a bigger propotion of verbs** and thus, must be discarded for the general approach.\n",
    "\n",
    "Another thing that we pointed out before is that paths should be the same with identical **switched** starting conditions. As we can see in Wu-Palmer, this is not the case and must also be discarded. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(wn.synset('woman.n.01').wup_similarity(wn.synset('girl.n.01')))\n",
    "print(wn.synset('girl.n.01').wup_similarity(wn.synset('woman.n.01')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because of this, our decision is now between **Path Similarity** and the **Lin Similarity**. As we can see from the combined analysis of the sum of values and the difference between local maximums and minimums, **Lin gives more accurate scores**, yielding **higher numbers in the overall matrix (total sum: 14.464)** and having a **greater difference between the similar and non-similar words (0.574)**. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions\n",
    "\n",
    "Over the development of this lab, we have calculated the most frequent WordeNet synsets and their least common subsumers. We have also analyzed their similarity value according to 4 different algorithms and have appllied normalization when needed. \n",
    "\n",
    "Another thing to highlight is that the HiddenMarkovModel looks really efficient timewise. It is likely that its just not in the desired set of conditions regarding the amount of data to perform correctly. \n",
    "\n",
    "Based on our analysis, we have selected the **Lin-Similarity as the best performing algorithm**. \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
