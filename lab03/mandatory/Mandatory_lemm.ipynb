{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# figure out of those imports are needed \n",
    "import nltk\n",
    "from nltk.metrics import jaccard_distance\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk import pos_tag\n",
    "from scipy.stats import pearsonr\n",
    "pairs = []\n",
    "tests = []\n",
    "tests_lem = []\n",
    "standard = []\n",
    "lem1 = []\n",
    "lem2 = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "for line in open('./trial/STS.input.txt','r'):\n",
    "    line = line.strip().split(\"\\t\")\n",
    "    pairs.append(line[1:])\n",
    "    \n",
    "for line in open('./trial/STS.gs.txt','r'):\n",
    "    line = line.strip().split(\"\\t\")\n",
    "    standard.append(int(line[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "wnl = WordNetLemmatizer()\n",
    "def lemmatize(p):\n",
    "    if p[1][0] in {'N','V'}:\n",
    "        return wnl.lemmatize(p[0].lower(), pos=p[1][0].lower())\n",
    "    return p[0].lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for pair in pairs:\n",
    "    sentence = \" \".join(pair)\n",
    "    tok_sen = nltk.sent_tokenize(sentence)\n",
    "    \n",
    "    # tokenizer\n",
    "    a = [nltk.word_tokenize(s) for s in tok_sen]\n",
    "        \n",
    "    w1 = set(a[0])\n",
    "    w2 = set(a[1])\n",
    "    \n",
    "    wordtype1 = pos_tag(w1)\n",
    "    lem1 = set([lemmatize(w) for w in wordtype1])\n",
    "    \n",
    "    wordtype2 = pos_tag(w2)\n",
    "    lem2 = set([lemmatize(w) for w in wordtype2])\n",
    "    \n",
    "    jaccard_similarity = 1 - jaccard_distance(w1, w2)\n",
    "    jaccard_similarity_lem = 1 - jaccard_distance(lem1, lem2)\n",
    "    tests.append(jaccard_similarity)\n",
    "    tests_lem.append(jaccard_similarity_lem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5, 4, 3, 2, 1, 0]\n",
      "[0.3076923076923077, 0.26315789473684215, 0.33333333333333337, 0.4545454545454546, 0.23076923076923073, 0.13793103448275867]\n",
      "[0.33333333333333337, 0.4117647058823529, 0.4285714285714286, 0.4545454545454546, 0.16666666666666663, 0.13793103448275867]\n"
     ]
    }
   ],
   "source": [
    "pearsonr(standard[0:6], tests[0:6])[0]\n",
    "\n",
    "print(standard[0:6])\n",
    "print(tests[0:6])\n",
    "print(tests_lem[0:6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6535131151331016\n"
     ]
    }
   ],
   "source": [
    "print(pearsonr(standard[0:6], tests_lem[0:6])[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
