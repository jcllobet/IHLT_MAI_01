{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import re\n",
    "import numpy as np\n",
    "import operator\n",
    "from threading import active_count\n",
    "from multiprocessing import Pool\n",
    "from nltk.collocations import TrigramCollocationFinder\n",
    "from nltk.metrics.scores import accuracy\n",
    "from nltk.metrics import ConfusionMatrix\n",
    "\n",
    "languages = ['deu', 'eng', 'fra', 'ita', 'nld', 'spa']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextProcessor():\n",
    "    \n",
    "    @staticmethod\n",
    "    def clean_string(string):\n",
    "        punctuation_marks_regex = r'[\\n\\t/\\d\\':,-_\\(\\)\\.\\?\\\";!]'\n",
    "        punctuation_free_text = re.sub(punctuation_marks_regex, '', string).strip()\n",
    "        lower_puntuation_free_text = punctuation_free_text.lower()\n",
    "        lower_puntuation_and_spaces_free_text = re.sub(' +', ' ', lower_puntuation_free_text)\n",
    "        return lower_puntuation_and_spaces_free_text\n",
    "\n",
    "    @staticmethod\n",
    "    def call(text, freq_filter=0):\n",
    "        corpora = TrigramCollocationFinder.from_words(\n",
    "            TextProcessor.clean_string(text)\n",
    "        )\n",
    "        corpora.apply_freq_filter(freq_filter)\n",
    "        return corpora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Corpus:\n",
    "    LAMBDA = 1\n",
    "    \n",
    "    def __init__(self, text):\n",
    "        self.corpora = self.process_text(text)\n",
    "        \n",
    "        self.counts = {}\n",
    "        self.lidstone_probabilities = {}\n",
    "        \n",
    "        self._len = None\n",
    "        self._set_len = None    \n",
    "        \n",
    "    def process_text(self, text):\n",
    "        return TextProcessor.call(text, 5)\n",
    "    \n",
    "    def lidstone_probability(self, n_gram):            \n",
    "        if not n_gram in self.lidstone_probabilities:\n",
    "            self.lidstone_probabilities[n_gram] = (self.count(n_gram) + Corpus.LAMBDA)\\\n",
    "                / (len(self) + self.set_len() * Corpus.LAMBDA)\n",
    "\n",
    "        return self.lidstone_probabilities[n_gram]\n",
    "    \n",
    "    def count(self, n_gram):\n",
    "        return self.corpora.ngram_fd[n_gram] if n_gram in self.corpora.ngram_fd else 0\n",
    "    \n",
    "    def set_len(self):\n",
    "        if not self._set_len: self._set_len = len(self.corpora.ngram_fd)\n",
    "        return self._set_len\n",
    "    \n",
    "    def __len__(self):\n",
    "        if not self._len: self._len = sum(self.corpora.ngram_fd.values())\n",
    "        return self._len\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return f'<Corpus>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LanguageClassifier():\n",
    "    \n",
    "    def __init__(self, training_set):\n",
    "        \"\"\"\n",
    "        Arguments:\n",
    "        training_set(Map) -- map cotaining the corpus as values and the lang name as key\n",
    "        \"\"\"\n",
    "        self.training_set = training_set\n",
    "    \n",
    "    def classify(self, text):\n",
    "        processed_text = TextProcessor.call(text).ngram_fd.keys()\n",
    "        return max({\n",
    "            lang: self.calc_probability(processed_text, corpus) \n",
    "            for lang, corpus in self.training_set.items()\n",
    "        }.items(), key=operator.itemgetter(1))[0]\n",
    "    \n",
    "    def calc_probability(self, n_grams, corpus):\n",
    "        return sum([\n",
    "            np.log(corpus.lidstone_probability(n_gram))\n",
    "            for n_gram in n_grams\n",
    "        ])\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return f'<LanguageClassifier training_set={self.training_set}>'\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_time = time.time()\n",
    "\n",
    "def read_file_to_corpus(lang):\n",
    "    with open(f'./given/langId/{lang}_trn.txt', 'r') as raw_text:\n",
    "        return (lang, Corpus(raw_text.read()))\n",
    "                \n",
    "with Pool(active_count()) as pool:\n",
    "    train_languages_corpus = pool.map(read_file_to_corpus, languages)\n",
    "                \n",
    "cls = LanguageClassifier({ c[0]: c[1] for c in train_languages_corpus })\n",
    "\n",
    "train_time = int(time.time() - train_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_corpus = []\n",
    "for lang in languages:\n",
    "    with open(f'./given/langId/{lang}_tst.txt', 'r') as raw_text:\n",
    "        [test_corpus.append((lang, line)) for line in raw_text.readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_time = time.time()\n",
    "\n",
    "def classify(line):\n",
    "    return {\n",
    "        'line': line[1],\n",
    "        'cls': cls.classify(line[1]),\n",
    "        'actual': line[0]\n",
    "    }\n",
    "\n",
    "with Pool(active_count()) as pool:\n",
    "    classification = pool.map(classify, test_corpus)\n",
    "\n",
    "test_time = int(time.time() - test_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = [cls['cls'] for cls in classification]\n",
    "actual = [cls['actual'] for cls in classification]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Learning time: 76 seconds.\n",
      "Test time: 68 seconds.\n",
      "Accuracy is 0.9984994247794988\n",
      "Confussion_matrix:\n",
      "    |    d    e    f    i    n    s |\n",
      "    |    e    n    r    t    l    p |\n",
      "    |    u    g    a    a    d    a |\n",
      "----+-------------------------------+\n",
      "deu |<9975>   6    .    1    6    2 |\n",
      "eng |    .<9982>   1    1    3    . |\n",
      "fra |    .    8<9982>   3    3    4 |\n",
      "ita |    1    7    3<9978>   .   11 |\n",
      "nld |    5    9    .    3<9982>   1 |\n",
      "spa |    .    3    2    7    .<9988>|\n",
      "----+-------------------------------+\n",
      "(row = reference; col = test)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"\"\"\n",
    "Learning time: {train_time} seconds.\n",
    "Test time: {test_time} seconds.\n",
    "Accuracy is {accuracy(actual, classes)}\n",
    "Confussion_matrix:\n",
    "{ConfusionMatrix(actual, classes).pretty_format()}\n",
    "\"\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
