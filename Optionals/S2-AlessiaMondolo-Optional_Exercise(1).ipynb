{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optional exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**First, we crete a function to do the preprocessing of the text.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import re\n",
    "from itertools import islice\n",
    "from nltk.collocations import TrigramCollocationFinder\n",
    "import math\n",
    "from nltk.metrics.scores import accuracy\n",
    "from nltk.metrics import ConfusionMatrix\n",
    "\n",
    "def preprocess(line):\n",
    "    #Remove all the digits and punctuation from data\n",
    "    line = re.sub(r'(\\d|[^\\w ])', ' ', line)\n",
    "    #Remove spaces at the beginning of the line\n",
    "    line = re.sub(r'^[ ]+', '', line)\n",
    "    #Remove spaces at the end of the line\n",
    "    line = line.rstrip()\n",
    "    #Convert all the texts to lower case\n",
    "    line = line.lower()\n",
    "    #Replace continuous white spaces by a single one\n",
    "    line = re.sub(r'[ ]+', ' ', line)\n",
    "    return line"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Then, we read the training texts and preprocess them. We also make sure to remove all the trigrams that occur less then 5 times in the training corpus.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "languages = ['spa', 'nld', 'ita', 'fra', 'eng', 'deu']\n",
    "\n",
    "languages_dict = {}\n",
    "for lang in languages:\n",
    "    preprocessed_text = ''\n",
    "    with open('./langId/'+ lang +'_trn.txt') as f:\n",
    "        for line in f:\n",
    "            preprocessed_text = '  '.join([preprocessed_text, preprocess(line)])\n",
    "\n",
    "    finder = TrigramCollocationFinder.from_words(preprocessed_text)\n",
    "    finder.apply_freq_filter(5)\n",
    "    languages_dict[lang] = finder.ngram_fd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Finally, we read the test texts and for each sentence of each language we do the preprocessing and then calculate the probabilites for each sentence to belong to each of the possible language, and we assign to the sentence the language with the higher probability.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_languages = []\n",
    "predicted_languages = []\n",
    "for language in languages:\n",
    "    with open('./langId/'+language+'_tst.txt') as f:\n",
    "        for line in f:\n",
    "            test_text = preprocess(line)\n",
    "            finder = TrigramCollocationFinder.from_words(test_text)\n",
    "\n",
    "            probabilites = {}\n",
    "            for lang in languages:\n",
    "                p = sum(math.log((languages_dict[lang][tr[0]] + 1)*tr[1]) for tr in finder.ngram_fd.items())\n",
    "                probabilites[lang]= p - math.log(languages_dict[lang].N()+1)*finder.ngram_fd.N()\n",
    "            sorted_probabilites = sorted(probabilites.items(), key=lambda x: x[1], reverse=True)\n",
    "            predicted = sorted_probabilites[0][0]\n",
    "            real_languages.append(language)\n",
    "            predicted_languages.append(predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Once our model is tested, we calculate the accuracy of the model.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.9983993864314654\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy: ', accuracy(real_languages,predicted_languages))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Finally, we print the confusion matrix.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "    |    d    e    f    i    n    s |\n",
      "    |    e    n    r    t    l    p |\n",
      "    |    u    g    a    a    d    a |\n",
      "----+-------------------------------+\n",
      "deu |<9979>   5    .    .    5    1 |\n",
      "eng |    .<9982>   1    1    3    . |\n",
      "fra |    .   10<9980>   3    3    4 |\n",
      "ita |    .   13    4<9977>   1    5 |\n",
      "nld |    6   11    .    3<9978>   2 |\n",
      "spa |    .    5    1    9    .<9985>|\n",
      "----+-------------------------------+\n",
      "(row = reference; col = test)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cm = ConfusionMatrix(real_languages,predicted_languages)\n",
    "print('Confusion Matrix:')\n",
    "print(cm.pretty_format())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
