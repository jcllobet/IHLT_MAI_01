{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optional exercise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import wordnet as wn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Develop a function to search and show the shortest path between two noun synset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def dict_hyper(synset_word):\n",
    "    \"\"\"\n",
    "    Returns a dictionary containing every hypernyms from the \n",
    "    'synset_word' given up to the root and their path.\n",
    "    \n",
    "    If a word is seen more than one time at different parts\n",
    "    of the tree, this will be seen in the output dictionary\n",
    "    as the first time it was computed.\n",
    "    \"\"\"\n",
    "    #Initial dictionary:\n",
    "    dictionary = {synset_word.name():[synset_word]}\n",
    "    #Initial depth:\n",
    "    maxdepth = 1\n",
    "    \n",
    "    while maxdepth <= synset_word.max_depth():\n",
    "        #New dictionary for the new layer of depth\n",
    "        dic2 = {}\n",
    "        #Now we are going to iterate over all existing words in our dictionary\n",
    "        for i in dictionary.keys():\n",
    "            #And select the words of the last computed layer\n",
    "            if len(dictionary[i]) == maxdepth:\n",
    "                #For those words we are going to create a dictionary of the parent words\n",
    "                dic = {a.name(): [a] for a in dictionary[i][0].hypernyms()}\n",
    "                #And extend the child words from the original dictionary to get the path\n",
    "                for j in dic.keys():\n",
    "                    dic[j].extend(dictionary[i])\n",
    "                #For this layer we are going to put this word into our aid dictionary\n",
    "                dic2.update(dic)\n",
    "        #Now we find the intersecting values in both dictionaries and change their names\n",
    "        inters = [value for value in list(dictionary.keys()) if value in list(dic2.keys())]\n",
    "        inters\n",
    "        for i in inters:\n",
    "            dic2.pop(i)\n",
    "        #Finally we update our master dictionary and add one to the max depth counter\n",
    "        dictionary.update(dic2)\n",
    "        maxdepth+=1\n",
    "    \n",
    "    return dictionary\n",
    "\n",
    "def printPath(path1, path2):\n",
    "    \"\"\"\n",
    "    Prints the path between two lists.\n",
    "    \"\"\"\n",
    "    if len(path1)>=len(path2):\n",
    "        for i in range(len(path1)):\n",
    "            print(' '*i + str(path1[-1-i]))\n",
    "        for j in range(1,len(path2)):\n",
    "            print(' '*(len(path1)-j-1) + str(path2[j]))\n",
    "    else:\n",
    "        printPath(path2, path1)\n",
    "        \n",
    "def searchShortestPath(synset1, synset2):\n",
    "    \"\"\"\n",
    "    This functions solves the Optional exercise.\n",
    "    \"\"\"\n",
    "    #First we create the dictionaries containint the paths to all their hypernyms:\n",
    "    dict1 = dict_hyper(synset1)\n",
    "    dict2 = dict_hyper(synset2)\n",
    "    \n",
    "    #Then we create a dictionary of the distances to each hyperonym:\n",
    "    distance_dict1 = {i:len(dict1[i]) for i in dict1}\n",
    "    distance_dict2 = {i:len(dict2[i]) for i in dict2}\n",
    "    \n",
    "    #Let's find the intersecting words\n",
    "    intersect = [value for value in list(dict1.keys()) if value in list(dict2.keys())]\n",
    "    \n",
    "    #And get the minimum distance between intersecting hyperonyms:\n",
    "    distance_words = {i:distance_dict1[i]+distance_dict2[i] for i in intersect}\n",
    "    min_distance = min(distance_words, key=distance_words.get)\n",
    "    \n",
    "    path1 = dict1[min_distance]\n",
    "    path2 = dict2[min_distance]\n",
    "    \n",
    "    #Finally we print the results:\n",
    "    print('The minimum path distance is ' + str(distance_words[min_distance]-2))\n",
    "    printPath(path1, path2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Apply it to show the shortest path between dog.n.01 and cat.n.01."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The minimum path distance is 4\n",
      "Synset('dog.n.01')\n",
      " Synset('canine.n.02')\n",
      "  Synset('carnivore.n.01')\n",
      " Synset('feline.n.01')\n",
      "Synset('cat.n.01')\n"
     ]
    }
   ],
   "source": [
    "dog = wn.synset('dog.n.01')\n",
    "cat = wn.synset('cat.n.01')\n",
    "searchShortestPath(dog, cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
