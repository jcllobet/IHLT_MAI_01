{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optional Exercise - Session 5 B\n",
    "\n",
    "### Students: Nafis Banirazi & Jan Carbonell\n",
    "\n",
    "### Lab Objective: \n",
    "Statement (unsupervised polarity system):\n",
    "- Get the first synset (most frequent) of one of the next alternatives:\n",
    "    - nouns, verbs, adjectives and adverbs\n",
    "    - nouns, adjectives and adverbs\n",
    "    - only adjectives\n",
    "- Sum all the positive scores and negative ones to get the polarity\n",
    "- Apply the system to the movie reviews corpus and give the accuracy\n",
    "- Give some conclusions about the work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import movie_reviews as mr\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk import pos_tag\n",
    "from nltk.corpus import sentiwordnet as swn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_valid_pairs(original_pairs):\n",
    "    valid_pairs = []\n",
    "    for word, tag in original_pairs:\n",
    "        if tag.startswith('N'):\n",
    "            valid_pairs.append((word, wn.NOUN))\n",
    "        elif tag.startswith('V'):\n",
    "            valid_pairs.append((word, wn.VERB))\n",
    "        elif tag.startswith('J'):\n",
    "            valid_pairs.append((word, wn.ADJ))\n",
    "        elif tag.startswith('R'):\n",
    "            valid_pairs.append((word, wn.ADV))\n",
    "    return valid_pairs\n",
    "\n",
    "def unsupervised_polarity_system(words):\n",
    "    pos = pos_tag(words)\n",
    "    valid_pairs = set(get_valid_pairs(pos))\n",
    "    \n",
    "    polarity = 0\n",
    "    for word, tag in valid_pairs:\n",
    "        synsets = wn.synsets(word, tag)\n",
    "        if len(synsets) > 0:\n",
    "            synset = synsets[0]\n",
    "            sentiSynset = swn.senti_synset(synset.name())\n",
    "            polarity += sentiSynset.pos_score() - sentiSynset.neg_score()\n",
    "    return polarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total negatives:  1000\n",
      "Correctly identified as negatives:  284\n",
      "Accuracy:  0.284\n",
      "\n",
      "Total positives:  1000\n",
      "Correctly identified as positives:  881\n",
      "Accuracy:  0.881\n"
     ]
    }
   ],
   "source": [
    "neg_count = 0\n",
    "for fid in mr.fileids('neg'):\n",
    "    words = mr.words(fid)\n",
    "    polarity = unsupervised_polarity_system(words)\n",
    "    if(polarity<0):\n",
    "        neg_count+=1\n",
    "print('Total negatives: ', len(mr.fileids('neg')))\n",
    "print('Correctly identified as negatives: ', neg_count)\n",
    "print('Accuracy: ', neg_count/len(mr.fileids('neg')))\n",
    "print()\n",
    "\n",
    "pos_count = 0\n",
    "for fid in mr.fileids('pos'):\n",
    "    words = mr.words(fid)\n",
    "    polarity = unsupervised_polarity_system(words)\n",
    "    if(polarity>0):\n",
    "        pos_count+=1\n",
    "print('Total positives: ', len(mr.fileids('pos')))\n",
    "print('Correctly identified as positives: ', pos_count)\n",
    "print('Accuracy: ', pos_count/len(mr.fileids('pos')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5825\n"
     ]
    }
   ],
   "source": [
    "total_accuracy = (neg_count+pos_count)/(len(mr.fileids('neg'))+len(mr.fileids('pos')))\n",
    "print(total_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions\n",
    "We are able predict positive and negative sentiments with a somewhat reasonable accuracy. It is relevant that not all negative words carry polarity and that perhaps, analyzing sentences as a whole is not the best method. Negatives seem much more harder to identify, possible due to the way the english language is structured, sentences are also constructed in that way (positive thoughts are shared openly while negative one's are often more subtle). "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
